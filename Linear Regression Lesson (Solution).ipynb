{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro To Data Science With Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Linear Regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excercise, you'll utilize the Linear Regression model from Scikit-Learn to predict housing prices in Boston.\n",
    "\n",
    "Linear regression is the fundamental building block of data science and analytics. If you ever venture into data science, this will most likely be the first model you're taught.\n",
    "\n",
    "\n",
    "Linear regression models are very simple, interpretable, and somewhat flexible. The goal is to predict a continuous output variable (e.g. MPG, prices, etc.) from a set of predictor variables, known as features.\n",
    "\n",
    "\n",
    "Within industry, you'll almost always try the linear regression before moving to advanced models, such as GBM, random forests, or neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary libraries to run the notebook. Press `Shift + Enter` to run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the boston dataset. This is a dataset that's installed within Scikit-Learn.\n",
    "\n",
    "The goal with this exercise: predict the housing price, using other columns (features) in the dataset.\n",
    "\n",
    "Load the Boston housing data with the line below.\n",
    "\n",
    "`boston = load_boston()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, separate the data into the features and target using the following code:\n",
    "\n",
    "`y = boston.target`\n",
    "\n",
    "`boston = pd.DataFrame(boston.data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = boston.target\n",
    "\n",
    "boston = pd.DataFrame(boston.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the boston dataset using the following code. The `head` method prints out the first 5 lines of your data.\n",
    "\n",
    "`boston.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns don't have any labels! This happens with some datasets. Assuming you have a data dictionary, you can label the columns. For the time being, add this line into the cell below, and call the `head` method on the DataFrame again.\n",
    "\n",
    "Refer to the `data_dictionary.pdf` document to see what each column name refers to.\n",
    "\n",
    "\n",
    "`boston.columns = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']`\n",
    "\n",
    "`boston.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   ptratio   black  lstat  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.columns = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is labeled, we have a better sense of what each column means.\n",
    "\n",
    "To reiterate, we'll be predicting the housing prices using all of these columns (features). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in the right format, we can plot a correlation matrix. This shows us what features are correlated with each other.\n",
    "\n",
    "For reference, -1 is uncorrelated, and 1 is highly correlated. Run the function below to look at the numbers.\n",
    "\n",
    "\n",
    "\n",
    "`boston.corr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crim</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199458</td>\n",
       "      <td>0.404471</td>\n",
       "      <td>-0.055295</td>\n",
       "      <td>0.417521</td>\n",
       "      <td>-0.219940</td>\n",
       "      <td>0.350784</td>\n",
       "      <td>-0.377904</td>\n",
       "      <td>0.622029</td>\n",
       "      <td>0.579564</td>\n",
       "      <td>0.288250</td>\n",
       "      <td>-0.377365</td>\n",
       "      <td>0.452220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zn</th>\n",
       "      <td>-0.199458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>0.404471</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chas</th>\n",
       "      <td>-0.055295</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>0.417521</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>-0.219940</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.350784</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>-0.377904</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad</th>\n",
       "      <td>0.622029</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>0.579564</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptratio</th>\n",
       "      <td>0.288250</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>-0.377365</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstat</th>\n",
       "      <td>0.452220</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim        zn     indus      chas       nox        rm       age  \\\n",
       "crim     1.000000 -0.199458  0.404471 -0.055295  0.417521 -0.219940  0.350784   \n",
       "zn      -0.199458  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "indus    0.404471 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "chas    -0.055295 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "nox      0.417521 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "rm      -0.219940  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "age      0.350784 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "dis     -0.377904  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "rad      0.622029 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "tax      0.579564 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "ptratio  0.288250 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "black   -0.377365  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "lstat    0.452220 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "\n",
       "              dis       rad       tax   ptratio     black     lstat  \n",
       "crim    -0.377904  0.622029  0.579564  0.288250 -0.377365  0.452220  \n",
       "zn       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
       "indus   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
       "chas    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
       "nox     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
       "rm       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
       "age     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
       "dis      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
       "rad     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
       "tax     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
       "ptratio -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
       "black    0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
       "lstat   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the numbers from the correlation matrix, but it's not as easy to view or interpret as a plot.\n",
    "\n",
    "To see correlations plotted by color, run the `correlation_matrix_plot` function below.\n",
    "\n",
    "Examine the correlations in the lower triangle, then answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAH3CAYAAACWz3r3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ba6fb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def correlation_matrix_plot(n_top_features, df):\n",
    "    feats = n_top_features\n",
    "    corr = df[list(feats)].corr()\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    labels = corr.where(np.triu(np.ones(corr.shape)).astype(np.bool))\n",
    "    labels = labels.round(2)\n",
    "    labels = labels.replace(np.nan,' ', regex=True)\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(9,9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    ax = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "correlation_matrix_plot(boston.columns,boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot above: \n",
    "\n",
    "1. What features are highly correlated?\n",
    "\n",
    "> From looking at the correlations, `rad` and `tax` are shown to be heavily correlated. \n",
    "\n",
    "2. Which features are highly uncorrelated?\n",
    "\n",
    "> `lstat` is highly uncorrelated with `rm` and `dis`. Additionally, `dis` is highly uncorrelated with `indus`, `nox`, and `age`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Linear Regression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in the right format, we can begin to build the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to split the data. In data science, your data is split into two datasets.\n",
    "\n",
    "The first dataset is the *training* set. Building a model is referred to as \"training\", hence the moniker of a \"training\" data set. The second dataset is the *test* set. This is used to make predictions, and evaluate if our model is performing well.\n",
    "\n",
    "To split the data into training and test data sets, type the following line.\n",
    "\n",
    "`X_train, X_test, y_train, y_test = train_test_split(boston, y, test_size=0.20, random_state=42)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boston, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data being split, we'll now create the LinearRegression module. Write the line in the cell below:\n",
    "\n",
    "`model = LinearRegression()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're now ready to train the model. Write and run the following line:\n",
    "\n",
    "`model.fit(X_train, y_train)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Score Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can predict new values using the test set. Write the following code to predict the housing prices.\n",
    "\n",
    "`predictions = model.predict(X_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll look at the coefficients for our model. Coefficients describe the mathematical relationship between each independent feature(s) and the target variable. \n",
    "\n",
    "The sign of a regression coefficient tells you whether there is a positive or negative correlation between each independent variable and the dependent variable. A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease.\n",
    "\n",
    "The coefficient value signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding other variables in the model constant. This property of holding the other variables constant is crucial because it allows you to assess the effect of each variable in isolation from the others.\n",
    "\n",
    "`coefficients = pd.DataFrame(model.coef_, boston.columns).sort_values(by=0, ascending=False)`\n",
    "\n",
    "`print(coefficients)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "rm        4.432488\n",
      "chas      2.786767\n",
      "rad       0.262114\n",
      "indus     0.040731\n",
      "zn        0.030081\n",
      "black     0.012452\n",
      "age      -0.006240\n",
      "tax      -0.010639\n",
      "crim     -0.112463\n",
      "lstat    -0.509349\n",
      "ptratio  -0.916399\n",
      "dis      -1.448485\n",
      "nox     -17.240635\n"
     ]
    }
   ],
   "source": [
    "coefficients = pd.DataFrame(model.coef_, boston.columns).sort_values(by=0, ascending=False)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to gain an understanding of how our model is performing, we'll score the model against three metrics: R squared, mean squared error, and mean absolute error. Write the following lines of code to get your output.\n",
    "\n",
    "`print(\"R Squared Score: \", r2_score(y_test, predictions))`\n",
    "\n",
    "`print(\"Mean Squared Error: \", mean_squared_error(y_test, predictions))`\n",
    "\n",
    "`print(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared Score:  0.668482575397\n",
      "Mean Squared Error:  24.3114269297\n",
      "Mean Absolute Error:  3.19150897227\n"
     ]
    }
   ],
   "source": [
    "print(\"R Squared Score: \", r2_score(y_test, predictions))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, predictions))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Google R Squared, Mean Squared Error, and Mean Absolute Error. What do these metrics mean? What are the numbers telling you?\n",
    "2. What do you think could improve the model?\n",
    "3. What features do you think are not useful to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Google R Squared, Mean Squared Error, and Mean Absolute Error. What do these metrics mean? What are the numbers telling you?\n",
    "\n",
    "> R Squared (R^2) calculates how close the data is fitted to the line of best fit. A higher R^2 indicates a better fit; however, R^2 can't show you if the predictions are biased. \n",
    "\n",
    "> The Mean Squared Error tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the errors) and squaring them. The squaring is necessary to remove any negative signs. It also gives more weight to larger differences. Its called the mean squared error as youre finding the average of a set of errors.\n",
    "\n",
    "> The Mean Absolute Error (MAE) measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables. Expressed in words, the MAE is the average over the verification sample of the absolute values of the differences between forecast and the corresponding observation. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n",
    "\n",
    "\n",
    "2. What do you think could improve the model?\n",
    "\n",
    "> There are multiple items that can improve this model. One is using only a few specific features, as opposed to the entire set of features. You can also apply regularization, which is a way to make the model more generalized (and help prevent overfitting).\n",
    "\n",
    "\n",
    "3. What features do you think aren't useful to the model?\n",
    "\n",
    "> One feature that could be removed is the `black` feature, which indicates the proportion of blacks by town. This feature is one that involves too much bias, and should be excluded from analysis.\n",
    "\n",
    "> Addtionally, the `lstat` feature could be removed, which indicates lower status of the population (percent). Again, this introduces lots of bias, and may need to be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics By Jim - http://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
